<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://iguillenp.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://iguillenp.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-06-06T20:46:26+00:00</updated><id>https://iguillenp.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">PhD Research Stay in Torino</title><link href="https://iguillenp.github.io/blog/2024/phd-research-stay-24/" rel="alternate" type="text/html" title="PhD Research Stay in Torino"/><published>2024-04-01T00:00:00+00:00</published><updated>2024-04-01T00:00:00+00:00</updated><id>https://iguillenp.github.io/blog/2024/phd-research-stay-24</id><content type="html" xml:base="https://iguillenp.github.io/blog/2024/phd-research-stay-24/"><![CDATA[<h2 id="work-plan">Work plan</h2> <blockquote> <p><strong>Duration:</strong> 1 April to 7 July 2024</p> </blockquote> <p><strong>Main Objective:</strong> To conduct research in the area of Natural Language Processing (NLP), focusing on hate speech detection and political discourse analysis, with a special focus on Spanish and Italian discourses. Activities:</p> <ul> <li><em>Literature review</em>: Explore and review existing literature on hate speech detection and political discourse analysis in NLP. Analyse previous research related to case studies in Spanish and Italian.</li> <li><em>Collaboration with the Content-Centric Computing group</em>: Work in close collaboration with the researchers and students of the group. Participate in regular meetings to discuss research progress and receive feedback.</li> <li><em>Data collection</em>: Collect and prepare relevant datasets in Spanish and Italian for the analysis of hate and political discourses.</li> <li><em>Model development</em>: Design and develop NLP algorithms and models for hate speech detection and political discourse analysis. Implement natural language processing techniques for data pre-processing and analysis.</li> <li><em>Evaluation and validation</em>: Evaluate the performance of the developed algorithms and models using existing metrics and develop own if needed. Validate results through rigorous testing and statistical analysis.</li> <li><em>Preparation of reports and documents</em>: Document the research process, including methods, results and conclusions. Prepare technical reports and scientific papers for possible publication in relevant conferences and journals.</li> </ul> <p><strong>Participation in the LREC-COLING 2024 conference</strong>: Volunteer to attend the conference to learn about the latest developments in the field of NLP. Networking with other professionals and sharing research experiences.</p> <h2 id="activity-during-the-stay">Activity during the stay</h2> <ul> <li>I presented a poster at the COMETE (COMputer SciEnce DeparTmEnt) PhD Workshop on my activity in political discourse analysis through ontologies.</li> <li>I volunteered during the LREC-COLING 2024 conference and was able to attend the conference.</li> </ul>]]></content><author><name></name></author><category term="research-stay"/><summary type="html"><![CDATA[Details of my research stay in Turin from 1 April to 7 July 2024, focusing on NLP research on hate speech detection and political discourse analysis in Spanish and Italian.]]></summary></entry><entry><title type="html">2nd Cardiff NLP Summer Workshop</title><link href="https://iguillenp.github.io/blog/2023/cardiff/" rel="alternate" type="text/html" title="2nd Cardiff NLP Summer Workshop"/><published>2023-06-26T00:00:00+00:00</published><updated>2023-06-26T00:00:00+00:00</updated><id>https://iguillenp.github.io/blog/2023/cardiff</id><content type="html" xml:base="https://iguillenp.github.io/blog/2023/cardiff/"><![CDATA[<h2 id="evolution-of-political-discourse-in-madrid-a-case-study-in-the-transport-domain">Evolution of political discourse in Madrid: a case study in the transport domain</h2> <p>I presented a poster <a href="https://github.com/Ibaii99/2nd-Cardiff-NLP-Summer-Workshop/blob/main/POSTER_CARDIFF_IBAI.pdf">Evolution of political discourse in Madrid: a case study in the transport domain</a> in the <a href="https://2023.cardiffnlpworkshop.org">2nd Cardiff NLP Summer Workshop</a>.</p> <p>The Cardiff NLP Group is organising an in-person workshop on Natural Language Processing (NLP). It will take place on 26-27 June 2023 in Abacws, the brand-new building for the School of Computer Science and the School of Mathematics at Cardiff University. The workshop is especially intended to NLP practitioners and researchers, but everyone would be welcome. Registration is free, but the capacity is limited.</p> <h2 id="motivation">üß≠Motivation</h2> <p>Social networks play a fundamental role in political discourse. They have changed the way politics is made and consumed. Political parties use social media, such as Twitter, to share their opinion on news and events. During the electoral campaign, these social networks are a strategic tool to convince the electorate. The interaction generated on these networks generates ideological debates that have a direct impact on electoral results.</p> <p>The speech shared by these organisations on social media is usually different from the speech shared through other channels. The immediacy of social media and discussions can produce <strong>inconsistencies in the speech</strong> of organisations over time. This can involve false promises (discrepancy between rhetoric and action), changes of opinion, or contradictions around a given subject.</p> <p>The electoral campaign‚Äôs objective is to get as many votes as possible. This motivates political parties to share news that favours them or harms their opponents. Sometimes the veracity of the news is not checked and they share hoaxes, producing a <strong>bias</strong> in the electorate <strong>through fake news</strong>.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/cardiff24-1-480.webp 480w,/assets/img/posts/cardiff24-1-800.webp 800w,/assets/img/posts/cardiff24-1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/cardiff24-1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="Ô∏èproposed-solution">‚ö†Ô∏èProposed solution</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/cardiff24-2-480.webp 480w,/assets/img/posts/cardiff24-2-800.webp 800w,/assets/img/posts/cardiff24-2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/cardiff24-2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> Working with cross-channel content have several difficulties. To face these complications we propose an ontology-based approach. From the definition of ontologies ([‚Äú*specification of a conceptualization*‚Äù](http://www-ksl.stanford.edu/kst/what-is-an-ontology.html)), we find in them the way to specify the concepts, knowledge and relations we wanted to manage. We build an ontology in which the speeches produced by the same organisation in a temporal space coexist and can be exploited. We assume that a speech is any content published by the same entity, whatever its type, channel and size. This abstraction allow us to work with the speeches generated by any organisation at any time, regardless of the channel through where the information was published. These organisations could be governments, business, political parties, etc. It allow different organisations to coexist and be recognised. Both in the speeches they produce and in those in which they are mentioned, quoted or referenced. In addition, it allow the speeches to be divided by themes and by time. </div> </div> <h2 id="future-work">üîúFuture work</h2> <p>We defined several tasks that could be carried out as future work with our infrastructure:</p> <ol> <li>Discrepancy Identification between Rhetoric and Action. <ol> <li>Detect political parties social media posts that correspond to political proposals.</li> <li>Identify incompatible political proposals between parties. Or find similar ones.</li> <li>Identify political parties opinion in social media about other parties political proposals.</li> </ol> </li> <li>Inconsistency Detection in Political Speech. <ol> <li>Contradiction in the speech: Detect which political proposals that where criticised by a political party in the social media are present in its party manifesto.</li> <li>Inconsistencies in speech: Detect whether the above occurs but with the political manifesto of the previous or the following year.</li> <li>Detect changes of opinion about a certain topic. If several changes, track them.</li> </ol> </li> <li>Bias Measurement in Fake News. <ol> <li>Detect fake news.</li> <li>Detect if fake news are shared intentionally.</li> <li>Measure the effect of each fake new in the political campaign.</li> <li>Detect whether the agent regrets sharing it.</li> <li>Detect the source of the fake new, how it was created and with what intentions.</li> </ol> </li> <li>Enrich the knowledge graph with more information. <ol> <li>Add Facebook data.</li> <li>Add principal politicians data (both twitter and Facebook).</li> <li>Add new organisations. E. g.: Media as organisation, the posts on social media of the official account (if any) and the news published.</li> </ol> </li> <li>Digitise resources: Political Manifestos, News, Electoral Debates, etc.</li> </ol> <p>And more tasks ‚Ä¶</p> <h2 id="contact-us">üì®Contact us</h2> <p>Please contact us for collaborations, suggestion or questions at: ibai.guillen@upm.es</p>]]></content><author><name></name></author><category term="workshop"/><category term="poster"/><summary type="html"><![CDATA[Evolution of political discourse in Madrid: a case study in the transport domain]]></summary></entry><entry><title type="html">4th Summer Datathon on Linguistic Linked Open Data (SD-LLOD-22)</title><link href="https://iguillenp.github.io/blog/2022/qichwabase/" rel="alternate" type="text/html" title="4th Summer Datathon on Linguistic Linked Open Data (SD-LLOD-22)"/><published>2022-06-03T00:00:00+00:00</published><updated>2022-06-03T00:00:00+00:00</updated><id>https://iguillenp.github.io/blog/2022/qichwabase</id><content type="html" xml:base="https://iguillenp.github.io/blog/2022/qichwabase/"><![CDATA[<h2 id="dictionary-lodification-using-wikibase-quechua-language">Dictionary LODification using Wikibase: Quechua language</h2> <blockquote> <p><strong>Participants:</strong> Valeria Caruso, Ibai Guill√©n, Elwin Huaman</p> <p><strong>Tutor:</strong> David Lindemann</p> </blockquote> <p>Presented in the <a href="https://datathon2022.linkeddata.es/">4th Summer Datathon on Linguistic Linked Open Data (SD-LLOD-22)</a> was the <strong>winner of the best mini-project award</strong>.</p> <p>The <a href="https://datathon2022.linkeddata.es/">SD-LLOD-22</a> datathon has the main goal of giving people from industry and academia practical knowledge in the field of Linked Data applied to Linguistics. The final aim is to allow participants to migrate their own (or other‚Äôs) linguistic data and publish them as Linked Data on the Web and/or develop applications on top of Linguistic Linked Data. This datathon series is unique in its topic worldwide and continues from the success of the previous editions in 2015 and 2017 in Cercedilla (Spain), and in 2019 in Dagstuhl (Germany). This edition is sponsored and organised by COST (European Cooperation in Science and Technology) through NexusLinguarum, the ‚ÄúEuropean network for Web-centred linguistic data science‚Äù COST Action (CA18209, https://nexuslinguarum.eu/) and funded by the European Union.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/qichwabase-480.webp 480w,/assets/img/posts/qichwabase-800.webp 800w,/assets/img/posts/qichwabase-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/qichwabase.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> The aim of the project was to create a LOD version of a dictionary for the endangered South American language Quechua on Wikibase. The project began with the identification of suitable resources. Next there was the preprocessing and setup stage. This latter included: setting up QICHWABASE, programming a bot as well as normalising, cleaning and refining the data identified in the first phase. A pre-set ontological Wikibase application profile was identified as a model and was subsequently populated. Finally the data was published and a SPARQL endpoint made available. </div> </div>]]></content><author><name></name></author><category term="datathon"/><category term="project"/><summary type="html"><![CDATA[Dictionary LODification using Wikibase: Quechua language]]></summary></entry><entry><title type="html">Knowledge Prompting Hackathon</title><link href="https://iguillenp.github.io/blog/2022/london/" rel="alternate" type="text/html" title="Knowledge Prompting Hackathon"/><published>2022-06-03T00:00:00+00:00</published><updated>2022-06-03T00:00:00+00:00</updated><id>https://iguillenp.github.io/blog/2022/london</id><content type="html" xml:base="https://iguillenp.github.io/blog/2022/london/"><![CDATA[<h2 id="agent-guided-knowledge-engineering">Agent-guided Knowledge Engineering</h2> <blockquote> <p><strong>Participants:</strong> Ibai Guill√©n-Pacho, Carlos Golvano, Ryan Brate, Yannick Brunink</p> <p><strong>Mentor:</strong> Paul Groth</p> </blockquote> <p>This project was presented in the <a href="https://king-s-knowledge-graph-lab.github.io/knowledge-prompting-hackathon/">Knowledge Prompting Hackathon</a>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/london-project-480.webp 480w,/assets/img/posts/london-project-800.webp 800w,/assets/img/posts/london-project-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/london-project.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> The aim of the project was to develop an agent (i.e. LLM) to collaboratively create a comprehensive knowledge graph with a domain expert. This involves crafting both the graph's structure and content interactively, with the agent taking the lead. </div> </div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/london-group-480.webp 480w,/assets/img/posts/london-group-800.webp 800w,/assets/img/posts/london-group-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/london-group.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure>]]></content><author><name></name></author><category term="datathon"/><category term="project"/><summary type="html"><![CDATA[Agent-guided Knowledge Engineering]]></summary></entry><entry><title type="html">6th International Conference on Smart and Sustainable Technologies (SpliTech)</title><link href="https://iguillenp.github.io/blog/2021/guillen2021b/" rel="alternate" type="text/html" title="6th International Conference on Smart and Sustainable Technologies (SpliTech)"/><published>2021-09-08T00:00:00+00:00</published><updated>2021-09-08T00:00:00+00:00</updated><id>https://iguillenp.github.io/blog/2021/guillen2021b</id><content type="html" xml:base="https://iguillenp.github.io/blog/2021/guillen2021b/"><![CDATA[<h2 id="a-recommender-system-that-safeguards-the-user-privacy-through-federated-learning">A Recommender System that safeguards the user privacy through Federated Learning</h2> <p>I attended digitally to the <a href="https://2021.splitech.org/">6th International Conference on Smart and Sustainable Technologies (SpliTech)</a> conference. I presented a paper <em>A Recommender System that safeguards the user privacy through Federated Learning</em> <a class="citation" href="#guillen2021b">(Guill√©n et al., 2021)</a>, containing the results of my bachelor‚Äôs thesis <a class="citation" href="#guillen2021a">(Guill√©n-Pacho, 2021)</a>.</p> <p>Nowadays, there are more and more legal and ethical limitations when it comes to managing personal data. This is a serious problem for recommender systems (RS) or similar aplications since personal data (e.g. socioeconomic, demographics, behavioural, etc.) are the most useful for generating tailored correlations and predictions. To cope with this issue, this work proposes a recommender system that safeguards the user privacy by using a Federated Learning approach (FL). To this end, this article takes as the baseline an already existing centralized RS that uses all the data from users in a clear manner. This baseline RS is based on Factor Machines and it aims to employ persuasion strategies adapted to the user to increase energy awareness and change their consumption habits in the work environment. In order to test the performance of the FL-based distributed RS, the real dataset used (N=678) have been separated into four subsets mimicking a segmentation by country of origin (Austria, UK, Spain and Greece). Each country can create an artificial intelligence model suitable for its users that will be sent to a central server where the aggregation of models will take place and the improved global model will be returned back to each country. The simulation of this FL strategy is performed with four Raspberry Pi‚Äôs reflecting each country and an NVIDIA Jetson Nano is used as the aggregation server. The generated model not only increases the privacy of the users as no raw data travels to the central server but also improves the reliability of the recommendations.</p>]]></content><author><name></name></author><category term="conference"/><category term="paper"/><summary type="html"><![CDATA[A Recommender System that safeguards the user privacy through Federated Learning]]></summary></entry><entry><title type="html">5th International Conference on Smart and Sustainable Technologies (SpliTech)</title><link href="https://iguillenp.github.io/blog/2020/emaldi2020/" rel="alternate" type="text/html" title="5th International Conference on Smart and Sustainable Technologies (SpliTech)"/><published>2020-09-23T00:00:00+00:00</published><updated>2020-09-23T00:00:00+00:00</updated><id>https://iguillenp.github.io/blog/2020/emaldi2020</id><content type="html" xml:base="https://iguillenp.github.io/blog/2020/emaldi2020/"><![CDATA[<h2 id="blockchain-mediated-collaboration-of-citizens-in-open-government-processes">Blockchain-mediated Collaboration of Citizens in Open Government Processes</h2> <p>I contributed to <em>Blockchain-mediated Collaboration of Citizens in Open Government Processes</em> <a class="citation" href="#emaldi2020">(Emaldi et al., 2020)</a>, a work presented in the <a href="https://2020.splitech.org/">5th International Conference on Smart and Sustainable Technologies (SpliTech)</a> conference.</p> <p>This work explores how sustainable citizen collaboration to foster Open Government can be achieved by means of Blockchain-based solution. The technical feasibility and economic viability of a set of extensions of CKAN tool, bringing together Internet of People (IoP) related technologies such as Blockchain and crowdsourcing, to address sustainability in Open Government Portals is analysed. For that, a use case validation is performed, and the costs of its deployment assessed. The aim is to show how IoP promoting technologies enhance Public Administration (PA) and citizen collaboration to meet common interest objectives.</p>]]></content><author><name></name></author><category term="conference"/><category term="paper"/><summary type="html"><![CDATA[Blockchain-mediated Collaboration of Citizens in Open Government Processes]]></summary></entry></feed>