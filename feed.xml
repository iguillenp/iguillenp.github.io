<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://iguillenp.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://iguillenp.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-06-06T08:58:59+00:00</updated><id>https://iguillenp.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">PhD Research Stay in Torino</title><link href="https://iguillenp.github.io/blog/2024/phd-research-stay-24/" rel="alternate" type="text/html" title="PhD Research Stay in Torino"/><published>2024-04-01T00:00:00+00:00</published><updated>2024-04-01T00:00:00+00:00</updated><id>https://iguillenp.github.io/blog/2024/phd-research-stay-24</id><content type="html" xml:base="https://iguillenp.github.io/blog/2024/phd-research-stay-24/"><![CDATA[<h2 id="work-plan">Work plan</h2> <blockquote> <p><strong>Duration:</strong> 1 April to 7 July 2024</p> </blockquote> <p><strong>Main Objective:</strong> To conduct research in the area of Natural Language Processing (NLP), focusing on hate speech detection and political discourse analysis, with a special focus on Spanish and Italian discourses. Activities:</p> <ul> <li><em>Literature review</em>: Explore and review existing literature on hate speech detection and political discourse analysis in NLP. Analyse previous research related to case studies in Spanish and Italian.</li> <li><em>Collaboration with the Content-Centric Computing group</em>: Work in close collaboration with the researchers and students of the group. Participate in regular meetings to discuss research progress and receive feedback.</li> <li><em>Data collection</em>: Collect and prepare relevant datasets in Spanish and Italian for the analysis of hate and political discourses.</li> <li><em>Model development</em>: Design and develop NLP algorithms and models for hate speech detection and political discourse analysis. Implement natural language processing techniques for data pre-processing and analysis.</li> <li><em>Evaluation and validation</em>: Evaluate the performance of the developed algorithms and models using existing metrics and develop own if needed. Validate results through rigorous testing and statistical analysis.</li> <li><em>Preparation of reports and documents</em>: Document the research process, including methods, results and conclusions. Prepare technical reports and scientific papers for possible publication in relevant conferences and journals.</li> </ul> <p><strong>Participation in the LREC-COLING 2024 conference</strong>: Volunteer to attend the conference to learn about the latest developments in the field of NLP. Networking with other professionals and sharing research experiences.</p> <h2 id="activity-during-the-stay">Activity during the stay</h2> <ul> <li>I presented a poster at the COMETE (COMputer SciEnce DeparTmEnt) PhD Workshop on my activity in political discourse analysis through ontologies.</li> <li>I volunteered during the LREC-COLING 2024 conference and was able to attend the conference.</li> </ul>]]></content><author><name></name></author><category term="research-stay"/><category term="poster"/><category term="volunteer"/><summary type="html"><![CDATA[Details of my research stay in Turin from 1 April to 7 July 2024, focusing on NLP research on hate speech detection and political discourse analysis in Spanish and Italian.]]></summary></entry><entry><title type="html">Dictionary LODification using Wikibase: Quechua language</title><link href="https://iguillenp.github.io/blog/2022/qichwabase/" rel="alternate" type="text/html" title="Dictionary LODification using Wikibase: Quechua language"/><published>2022-06-03T00:00:00+00:00</published><updated>2022-06-03T00:00:00+00:00</updated><id>https://iguillenp.github.io/blog/2022/qichwabase</id><content type="html" xml:base="https://iguillenp.github.io/blog/2022/qichwabase/"><![CDATA[<p>Presented in the <a href="/news/2022/SD-LLOD-22/">4th Summer Datathon on Linguistic Linked Open Data (SD-LLOD-22)</a> was the <em>winner of the best mini-project award</em>.</p> <blockquote> <p><strong>Participants:</strong> Valeria Caruso, Ibai Guill√©n, Elwin Huaman</p> <p><strong>Tutor:</strong> David Lindemann</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/qichwabase-480.webp 480w,/assets/img/posts/qichwabase-800.webp 800w,/assets/img/posts/qichwabase-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/qichwabase.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> The aim of the project was to create a LOD version of a dictionary for the endangered South American language Quechua on Wikibase. The project began with the identification of suitable resources. Next there was the preprocessing and setup stage. This latter included: setting up QICHWABASE, programming a bot as well as normalising, cleaning and refining the data identified in the first phase. A pre-set ontological Wikibase application profile was identified as a model and was subsequently populated. Finally the data was published and a SPARQL endpoint made available. </div> </div>]]></content><author><name></name></author><category term="datathon"/><category term="project"/><summary type="html"><![CDATA[The aim of the project was to create a LOD version of a dictionary for the endangered South American language Quechua on Wikibase. The project began with the identification of suitable resources. Next there was the preprocessing and setup stage. This latter included: setting up QICHWABASE, programming a bot as well as normalising, cleaning and refining the data identified in the first phase. A pre-set ontological Wikibase application profile was identified as a model and was subsequently populated. Finally the data was published and a SPARQL endpoint made available.]]></summary></entry></feed>